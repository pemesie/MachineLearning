{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Part A: Model Code </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/DataScienceRepository/winequality-white.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_acidity = df['fixed acidity']\n",
    "volatile_acidity = df['volatile acidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class of distance functions\n",
    "class DistanceClass:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def EuclideanDistance(self, a, b):\n",
    "        norm = a - b\n",
    "        norm = norm.dot(norm)\n",
    "        return np.sqrt(norm)\n",
    "    \n",
    "    def ManhattanDistance(self, a, b):\n",
    "        norm = a - b\n",
    "        norm = norm.dot(norm)\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance:  464.1110898534962\n",
      "Manhattan distance:  215399.10372500002\n"
     ]
    }
   ],
   "source": [
    "x = DistanceClass()\n",
    "print(\"Euclidean distance: \", x.EuclideanDistance(fixed_acidity, volatile_acidity))\n",
    "print(\"Manhattan distance: \", x.ManhattanDistance(fixed_acidity, volatile_acidity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Accuracy and generalization error of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function returns the accuracy and the generalization error.\n",
    "Y is the target from the data set.\n",
    "Accuracy is the ratio of the correct predictions and the total number of predictions.\n",
    "General Error = 1 - accuracy \n",
    "'''\n",
    "\n",
    "def accuracyGeneralizationError(Y, Y_predicted ):\n",
    "#     accuracy = np.mean(Y == Y_predicted)\n",
    "#     gn = 1 - accuracy\n",
    "    count = 0\n",
    "    accuracy = 0\n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if (i == 0 and k == 0) or (i ==1 and k == 1) :\n",
    "            count += 1\n",
    "            \n",
    "    accuracy = count / len(Y)\n",
    "#     print(accuracy)\n",
    "    gn = 1 - accuracy\n",
    "    \n",
    "    return accuracy, gn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "def precision(Y, Y_predicted):\n",
    "    #truePositive = np.sum(Y == Y_predicted).astype(np.int)\n",
    "    truePositive = 0\n",
    "    totalTruePositive = 0\n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i ==1 and k == 1:\n",
    "            truePositive +=1\n",
    "            totalTruePositive +=1\n",
    "        if i == 0 and k == 1:\n",
    "            totalTruePositive +=1\n",
    "            \n",
    "    return truePositive / totalTruePositive   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "def recall(Y, Y_predicted):\n",
    "    #truePositive = np.sum(Y == Y_predicted).astype(np.int)\n",
    "    truePositive = 0\n",
    "    falseNegative = 0\n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i == 1 and k == 0:\n",
    "            falseNegative +=1\n",
    "        if i ==1 and k ==1:\n",
    "            truePositive += 1\n",
    "            \n",
    "    return truePositive / ( truePositive + falseNegative )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "def F1_score(Y, Y_predicted):\n",
    "    precision = precision(Y, Y_predicted)\n",
    "    recall = recall(Y, Y_predicted)    \n",
    "    \n",
    "    return ( (precision*recall) / (precision+recall) )*2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y, Y_predicted):\n",
    "    \n",
    "    matrix = np.zeros((2,2))\n",
    "    \n",
    "    truePositive= 0\n",
    "    trueNegative = 0 \n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    #truePositive = np.sum(Y == Y_predicted) #.astype(np.int)\n",
    "    \n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i == 0 and k == 0 :  \n",
    "            trueNegative +=1\n",
    "        if i == 1 and k == 0 :\n",
    "            falseNegative +=1\n",
    "        if i == 0 and k == 1 :\n",
    "            falsePositive += 1\n",
    "        if i == 1 and k ==1:\n",
    "            truePositive += 1\n",
    "     \n",
    "    matrix[0][0] = trueNegative\n",
    "    matrix[0][1] = falsePositive\n",
    "    matrix[1][1] = truePositive\n",
    "    matrix[1][0] = falseNegative\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Receiver Operating Characteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes arguments from cross_validation_predict()\n",
    "def plot_roc_curve(fpr, tpr, label =None):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # these 3 line below are unnecessaary\n",
    "#     conf_matrix = confusion_matrix(Y, Y_predicted)\n",
    "#     FPR = conf_matrix[0][1]/ (conf_matrix[0][1] + conf_matrix[0][0])\n",
    "#     TPR = recall(Y, Y_predicted)\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(fpr, tpr, color='darkorange', linewidth=8, label=label) \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.title('ROC Curve (Test Data)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. KNN Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object): # check if this parameter is needed on udemy\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.k = k\n",
    "        pass\n",
    "    \n",
    "    # distance_f is a function\n",
    "    def fit(self, training_features, training_labels, k, distance_f, **kwargs):\n",
    "        self.training_features = training_features\n",
    "        self.training_labels = training_labels\n",
    "        self.k = k\n",
    "        self.distance_f = distance_f\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    # predict\n",
    "    # Need to import:\n",
    "    # from sortedcontainers import SortedList\n",
    "    # import numpy as np\n",
    "    def predict(self, test_features):\n",
    "        \n",
    "        y = np.zeros(len(test_features))\n",
    "        \n",
    "        for i, x in enumerate(test_features):\n",
    "            # to store (distance, label) turples\n",
    "            sl = SortedList(key = self.k) \n",
    "            for j, xt in enumerate(self.training_features):\n",
    "                # compute the distance; here it is Euclidian distance. May need to change it or call the one of the disctance function wrote above\n",
    "                \"\"\" May have to change this code. Call the Euclidian distance function above\n",
    "                        euclidianDistance(x, xt)\n",
    "                \"\"\"\n",
    "                \n",
    "#                 temp = x - xt\n",
    "#                 distance = np.sqrt( temp.dot(temp)  )\n",
    "                \n",
    "                distance = euclidianDistance(x, xt)\n",
    "                \n",
    "                if len(sl) < self.k:\n",
    "                    sl.add( ( distance, self.training_labels[j] )  )\n",
    "                else:\n",
    "                    if distance < sl[-1][0]:\n",
    "                        del sl[-1]\n",
    "                        sl.add( ( distance, self.training_labels[j] )  )\n",
    "                        \n",
    "            \n",
    "            # count how many time a label appears in the sorted list\n",
    "            labelCount = {}\n",
    "            for _, l in sl:\n",
    "                labelCount[l] = labelCount.get(l, 0) + 1 # get() return 0 if label not found; the value otherwise\n",
    "            \n",
    "            # Classify; find the label that appears the most\n",
    "            maxCount = 0\n",
    "            label = -1\n",
    "            for l, labelCount in iteritems(labelCount):\n",
    "                if labelCount > maxCount:\n",
    "                    labelCount = maxCount\n",
    "                    label = l\n",
    "                    \n",
    "            y[i] = label\n",
    "            \n",
    "            \n",
    "        return y\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Austin's kNN class, fit, and predict functions\n",
    "import math\n",
    "\n",
    "class KNNModel:\n",
    "    \n",
    "    training_features = []\n",
    "    training_labels = []\n",
    "    k = 0\n",
    "    distance_f = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, training_features, training_labels, k, distance_f,\\\n",
    "            **kwargs):\n",
    "        self.training_features = training_features\n",
    "        self.training_labels = training_labels\n",
    "        self.k = k\n",
    "        self.distance_f = distance_f\n",
    "        arguments = {}\n",
    "    \n",
    "    def predict(self, test_features):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test instantiation method for KNNModel class\n",
    "def TestKNNModel():\n",
    "    df = pd.read_csv('datasets/DataScienceRepository/winequality-white.csv',\\\n",
    "                     delimiter=';')\n",
    "    training_features = np.array(df[['quality', 'fixed acidity']])\n",
    "    testKNNModel = KNNModel()\n",
    "    count = 0\n",
    "    training_labels = []\n",
    "    for item in training_features:\n",
    "        training_labels.append(\"Row Label #%i\" % count)\n",
    "        count = count + 1\n",
    "    training_labels = np.array(training_labels)\n",
    "    distanceObject = DistancesClass()\n",
    "    k = 2\n",
    "    testKNNModel.fit(training_features, training_labels, k, distanceObject.EuclideanDistance(3, 4))\n",
    "    print(\"Training features: \", testKNNModel.training_features)\n",
    "    print(\"Training labels: \", testKNNModel.training_labels)\n",
    "    print(\"K: \", testKNNModel.k)\n",
    "    print(\"Distance: \", testKNNModel.distance_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestKNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Read in the file as a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Convert target into a two-category variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality\"] = (df[\"quality\"] > 5).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Summary of each variable in terms of mean, standard deviation, and quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17 Shuffle the rows without affecting the order of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.sample(frac=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Generate pair plot using seaborn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out since it runs so long\n",
    "# # Matplotlib and seaborn for plotting\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "# from scipy import stats\n",
    "\n",
    "# # Calculate correlation coefficient\n",
    "# def corrfunc(x, y, **kws):\n",
    "#     r, _ = stats.pearsonr(x, y)\n",
    "#     ax = plt.gca()\n",
    "#     ax.annotate(\"r = {:.2f}\".format(r),\n",
    "#                 xy=(.1, .6), xycoords=ax.transAxes,\n",
    "#                size = 24)\n",
    "    \n",
    "# cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "#                              hue = 0.5, as_cmap=True)\n",
    "\n",
    "# sns.set_context(font_scale=2)\n",
    "\n",
    "# # Pair grid set up\n",
    "# g = sns.PairGrid(df)\n",
    "\n",
    "# # Scatter plot on the upper triangle\n",
    "# g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# # Distribution on the diagonal\n",
    "# g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# # Density Plot and Correlation coefficients on the lower triangle\n",
    "# g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "# g.map_lower(corrfunc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant features\n",
    "\"\"\"\n",
    "    Need to go over lecture notes. Read 'information gain'. It seems like correrlation is not suffisient to evaluate \n",
    "the independence between 2 variables\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Drop the redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Function to partition the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes 3 arguments: feature matrix (numpy array with rows representing data samples and columns representing \n",
    "features.), target vector (numpy array with labels corresponding to each row of the feature matrix), and t ( a real number\n",
    "to determine the size of partition). \n",
    "\"\"\"\n",
    "def partition(features, target, t):\n",
    "    \n",
    "    rowIndex = int((features.shape[0]*t))\n",
    "    \n",
    "    X_test = features.iloc[:rowIndex]\n",
    "    X_train = features.iloc[rowIndex:]\n",
    "\n",
    "    target_test = target.iloc[:rowIndex]\n",
    "    target_train = target.iloc[rowIndex:]\n",
    "    \n",
    "    return  X_train, X_test, target_train, target_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Naively run your kNN model on the train dataset with k = 5 and using Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"quality\"]\n",
    "features = df.drop([\"quality\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, target_train, target_test  = partition(features, target, t =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedList\n",
    "\n",
    "knn = KNN()\n",
    "knn.fit(X_train, target_train, 5, euclidianDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out since it errors\n",
    "# y_predicted = knn.predict(X_train)\n",
    "# y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><u><strong>22.</strong></u></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sFold(folds, data, labels, model, model_args, error_function):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data for k-fold cross validation\n",
    "ex = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Number of Rows and Columns\n",
    "def GetRowsCols(array):\n",
    "    print(\"Data array has %i data samples (rows)\" % array.shape[0])\n",
    "    print(\"Data array has %i features (columns)\" % array.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetRowsCols(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data array into n equal chunks\n",
    "def SPartician(array, n):\n",
    "    arr_split = np.array_split(array, n)\n",
    "    return arr_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPartician(ex, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
