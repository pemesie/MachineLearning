{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Part A: Model Code </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "def euclidianDistance(a,b):\n",
    "    #norm = a - b\n",
    "    #     norm = norm.dot(norm)\n",
    "    \n",
    "    return  np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Manhattan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ManhattanDistance(a,b):\n",
    "    norm = a - b\n",
    "    norm = norm.dot(norm)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Accuracy and generalization error of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function returns the accuracy and the generalization error.\n",
    "Y is the target from the data set.\n",
    "Accuracy is the ratio of the correct predictions and the total number of predictions.\n",
    "General Error = 1 - accuracy \n",
    "'''\n",
    "\n",
    "def accuracyGeneralizationError(Y, Y_predicted ):\n",
    "    accuracy = np.mean(Y == Y_predicted)\n",
    "    gn = 1 - accuracy\n",
    "#     count = 0\n",
    "#     accuracy = 0\n",
    "#     for i, k in zip(Y, Y_predicted):\n",
    "#         if (i == 0 and k == 0) or (i ==1 and k == 1) :\n",
    "#             count += 1\n",
    "            \n",
    "#     accuracy = count / len(Y)\n",
    "# #     print(accuracy)\n",
    "#     gn = 1 - accuracy\n",
    "    \n",
    "    return accuracy, gn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "def precision(Y, Y_predicted):\n",
    "    #truePositive = np.sum(Y == Y_predicted).astype(np.int)\n",
    "    truePositive = 0\n",
    "    totalTruePositive = 0\n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i ==1 and k == 1:\n",
    "            truePositive +=1\n",
    "            totalTruePositive +=1\n",
    "        if i == 0 and k == 1:\n",
    "            totalTruePositive +=1\n",
    "            \n",
    "    return truePositive / totalTruePositive   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "def recall(Y, Y_predicted):\n",
    "    #truePositive = np.sum(Y == Y_predicted).astype(np.int)\n",
    "    truePositive = 0\n",
    "    falseNegative = 0\n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i == 1 and k == 0:\n",
    "            falseNegative +=1\n",
    "        if i ==1 and k ==1:\n",
    "            truePositive += 1\n",
    "            \n",
    "    return truePositive / ( truePositive + falseNegative )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "def F1_score(Y, Y_predicted):\n",
    "    prec =0\n",
    "    prec = precision(Y, Y_predicted)\n",
    "    recal = 0\n",
    "    recal = recall(Y, Y_predicted)    \n",
    "    \n",
    "    return ( (prec*recal) / (prec+recal) )*2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y, Y_predicted):\n",
    "    \n",
    "    matrix = np.zeros((2,2))\n",
    "    \n",
    "    truePositive= 0\n",
    "    trueNegative = 0 \n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    #truePositive = np.sum(Y == Y_predicted) #.astype(np.int)\n",
    "    \n",
    "    for i, k in zip(Y, Y_predicted):\n",
    "        if i == 0 and k == 0 :  \n",
    "            trueNegative +=1\n",
    "        if i == 1 and k == 0 :\n",
    "            falseNegative +=1\n",
    "        if i == 0 and k == 1 :\n",
    "            falsePositive += 1\n",
    "        if i == 1 and k ==1:\n",
    "            truePositive += 1\n",
    "     \n",
    "    matrix[0][0] = trueNegative\n",
    "    matrix[0][1] = falsePositive\n",
    "    matrix[1][1] = truePositive\n",
    "    matrix[1][0] = falseNegative\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Receiver Operating Characteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes arguments from cross_validation_predict()\n",
    "def plot_roc_curve(fpr, tpr, label =None):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # these 3 line below are unnecessaary\n",
    "#     conf_matrix = confusion_matrix(Y, Y_predicted)\n",
    "#     FPR = conf_matrix[0][1]/ (conf_matrix[0][1] + conf_matrix[0][0])\n",
    "#     TPR = recall(Y, Y_predicted)\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(fpr, tpr, color='darkorange', linewidth=8, label=label) \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.title('ROC Curve (Test Data)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. KNN Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object): # check if this parameter is needed on udemy\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.k = k\n",
    "        pass\n",
    "    \n",
    "    # distance_f is a function\n",
    "    def fit(self, training_features, training_labels, k, distance_f, **kwargs):\n",
    "        \n",
    "        self.training_features = training_features\n",
    "        self.training_labels = training_labels\n",
    "        self.k = k\n",
    "        self.distance_f = distance_f\n",
    "        self.distance = 0\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    \n",
    "    # predict\n",
    "    # Need to import:\n",
    "    # from sortedcontainers import SortedList\n",
    "    # import numpy as np\n",
    "    \n",
    "    distance = 0\n",
    "    def predict(self, test_features):\n",
    "        \n",
    "        test_features = np.array(test_features)\n",
    "        \n",
    "        y = np.zeros(len(test_features))\n",
    "        \n",
    "        for i, x in enumerate(test_features):\n",
    "            # to store (distance, label) turples\n",
    "            sl = SortedList() \n",
    "           \n",
    "            for j, xt in enumerate(self.training_features):\n",
    "                # compute the distance; here it is Euclidian distance. May need to change it or call the one of the disctance function wrote above\n",
    "                \"\"\" May have to change this code. Call the Euclidian distance function above\n",
    "                        euclidianDistance(x, xt)\n",
    "                \"\"\"\n",
    "                \n",
    "                distance = self.distance_f(x, xt)\n",
    "                \n",
    "                if len(sl) < self.k:\n",
    "                   \n",
    "                    sl.add(  (distance, self.training_labels[j])   )\n",
    "                else:\n",
    "                    if distance < sl[-1][0]:\n",
    "                        del sl[-1]\n",
    "                        sl.add( ( distance, self.training_labels[j] )  )      \n",
    "            \n",
    "            # count how many time a label appears in the sorted list\n",
    "            labelCount = {}\n",
    "            for _, l in sl:\n",
    "                labelCount[l] = labelCount.get(l, 0) + 1 # get() return 0 if label not found; the value otherwise\n",
    "            \n",
    "            # Classify; find the label that appears the most\n",
    "            maxvotes = 0\n",
    "            label = -1\n",
    "            for l, labelCount in iteritems(labelCount):\n",
    "                if labelCount > maxvotes:\n",
    "                    maxvotes = labelCount\n",
    "                    label = l\n",
    "                    \n",
    "            y[i] = label\n",
    "            \n",
    "            \n",
    "        return y\n",
    "    \n",
    "#     def euclidianDistance(self,a,b):\n",
    "        \n",
    "#         norm = a - b\n",
    "#         norm = norm.dot(norm)\n",
    "#         return np.sqrt(norm)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Read in the file as a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:/Users/pemesie/Documents/UNL/UNL/CSCE 478 Intro Machine Learning/datasets/winequality-white.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d2f9dcf118f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/pemesie/Documents/UNL/UNL/CSCE 478 Intro Machine Learning/datasets/winequality-white.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'C:/Users/pemesie/Documents/UNL/UNL/CSCE 478 Intro Machine Learning/datasets/winequality-white.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"datasets/DataD/winequality-white.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Convert target into a two-category variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality\"] = (df[\"quality\"] > 5).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Summary of each variable in terms of mean, standard deviation, and quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17 Shuffle the rows without affecting the order of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.sample(frac=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Generate pair plot using seaborn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Matplotlib and seaborn for plotting\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "# from scipy import stats\n",
    "\n",
    "# # Calculate correlation coefficient\n",
    "# def corrfunc(x, y, **kws):\n",
    "#     r, _ = stats.pearsonr(x, y)\n",
    "#     ax = plt.gca()\n",
    "#     ax.annotate(\"r = {:.2f}\".format(r),\n",
    "#                 xy=(.1, .6), xycoords=ax.transAxes,\n",
    "#                size = 24)\n",
    "    \n",
    "# cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "#                              hue = 0.5, as_cmap=True)\n",
    "\n",
    "# sns.set_context(font_scale=2)\n",
    "\n",
    "# # Pair grid set up\n",
    "# g = sns.PairGrid(df)\n",
    "\n",
    "# # Scatter plot on the upper triangle\n",
    "# g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# # Distribution on the diagonal\n",
    "# g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# # Density Plot and Correlation coefficients on the lower triangle\n",
    "# g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "# g.map_lower(corrfunc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant features\n",
    "\"\"\"\n",
    "    Need to go over lecture notes. Read 'information gain'. It seems like correrlation is not suffisient to evaluate \n",
    "the independence between 2 variables\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Drop the redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Function to partition the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes 3 arguments: feature matrix (numpy array with rows representing data samples and columns representing \n",
    "features.), target vector (numpy array with labels corresponding to each row of the feature matrix), and t ( a real number\n",
    "to determine the size of partition). \n",
    "\"\"\"\n",
    "def partition(features, target, t):\n",
    "    \n",
    "    # Check if 'features' or 'target' is an instance of 'np.ndarray'\n",
    "    if isinstance(np_features, np.ndarray):\n",
    "        features = pd.DataFrame(np_features, index=range(np_features.shape[0]),\n",
    "                          columns=range(np_features.shape[1]))\n",
    "    if isinstance(target, np.ndarray):\n",
    "        target = pd.DataFrame(target, index=range(target.shape[0]),\n",
    "                          columns=range(target.shape[1]))\n",
    "        \n",
    "        \n",
    "    rowIndex = int((features.shape[0]*t))\n",
    "    \n",
    "    X_test = np.array( features.iloc[:rowIndex]   )\n",
    "    X_train = np.array( features.iloc[rowIndex:] )\n",
    "\n",
    "    target_test = np.array( target.iloc[:rowIndex]  )\n",
    "    target_train = np.array( target.iloc[rowIndex:] )\n",
    "    \n",
    "    return  X_train, X_test, target_train, target_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Naively run your kNN model on the train dataset with k = 5 and using Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"quality\"]\n",
    "features = df.drop([\"quality\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, target_train, target_test  = partition(features, target, t =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedList\n",
    "from future.utils import iteritems\n",
    "\n",
    "print(X_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "k= 15\n",
    "knn = KNN()\n",
    "knn.fit(X_train, target_train, k, euclidianDistance)\n",
    "\n",
    "y_predicted = knn.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" ??????????????????????????????????????????????\"\"\"\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Use accuracy and F1 score to compare your predictions to the expected label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a matrix: accurary and generalizationerror\n",
    "accuracy = accuracyGeneralizationError(target_train, y_predicted)\n",
    "accuracy[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = F1_score(target_train, y_predicted)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Standardize each feature of your training set (subtract mean and divide by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(dataset):\n",
    "    \n",
    "    for index in range( 0, dataset.shape[1] ):\n",
    "        mean = dataset[:,index].mean()\n",
    "        sdt = dataset[:, index].std()\n",
    "        dataset[:, index] =  ( dataset[:, index] * mean  ) / std\n",
    "        #print( dataset[:, index])\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = np.array(features)\n",
    "np_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = standardization(np_features)\n",
    "np_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Rerun the kNN model on the standardized data, find the accuracy and F1 score with the expected labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using 'np_features' here\n",
    "X_train, X_test, target_train, target_test  = partition(np_features, target, t =0.2)\n",
    "\n",
    "knn = KNN()\n",
    "knn.fit(X_train, target_train, 5, euclidianDistance)\n",
    "\n",
    "y_predicted = knn.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predicted.shape)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = accuracyGeneralizationError(target_train, y_predicted)\n",
    "print(\"Accuracy: \", accuracy[0] )\n",
    "\n",
    "F1 = F1_score(target_train, y_predicted)\n",
    "print(\"F1 score: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_train.shape, \"\\n\", y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
